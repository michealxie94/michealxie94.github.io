<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>007 详谈大模型训练和推理优化技术-csdn-王嘉宁 | michealxie94</title><meta name="author" content="michealxie94"><meta name="copyright" content="michealxie94"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="转载本文转载于：@csdn-王嘉宁 引言ChatGPT于2022年12月初发布，震惊轰动了全世界，发布后的这段时间里，一系列国内外的大模型训练开源项目接踵而至，例如Alpaca、BOOLM、LLaMA、ChatGLM、DeepSpeedChat、ColossalChat等。不论是学术界还是工业界，都有训练大模型来优化下游任务的需求。 然而，大量实验证明，在高质量的训练语料进行指令微调（Instru">
<meta property="og:type" content="article">
<meta property="og:title" content="007 详谈大模型训练和推理优化技术-csdn-王嘉宁">
<meta property="og:url" content="https://michealxie94.github.io/post/nlp007.html">
<meta property="og:site_name" content="michealxie94">
<meta property="og:description" content="转载本文转载于：@csdn-王嘉宁 引言ChatGPT于2022年12月初发布，震惊轰动了全世界，发布后的这段时间里，一系列国内外的大模型训练开源项目接踵而至，例如Alpaca、BOOLM、LLaMA、ChatGLM、DeepSpeedChat、ColossalChat等。不论是学术界还是工业界，都有训练大模型来优化下游任务的需求。 然而，大量实验证明，在高质量的训练语料进行指令微调（Instru">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://michealxie94.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2023-07-17T16:12:35.000Z">
<meta property="article:modified_time" content="2023-07-19T03:12:19.561Z">
<meta property="article:author" content="michealxie94">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://michealxie94.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://michealxie94.github.io/post/nlp007.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '007 详谈大模型训练和推理优化技术-csdn-王嘉宁',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-19 11:12:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/your_name.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="michealxie94"><span class="site-name">michealxie94</span></a></span><div id="he-plugin-simple"></div><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">007 详谈大模型训练和推理优化技术-csdn-王嘉宁</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-17T16:12:35.000Z" title="发表于 2023-07-18 00:12:35">2023-07-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-19T03:12:19.561Z" title="更新于 2023-07-19 11:12:19">2023-07-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NLP/">NLP</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NLP/LLM/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">103k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6:13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="007 详谈大模型训练和推理优化技术-csdn-王嘉宁"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="转载"><a href="#转载" class="headerlink" title="转载"></a><strong>转载</strong></h2><p>本文转载于：<a target="_blank" rel="noopener" href="https://wjn1996.blog.csdn.net/article/details/130764843">@csdn-王嘉宁</a></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>ChatGPT于2022年12月初发布，震惊轰动了全世界，发布后的这段时间里，一系列国内外的大模型训练开源项目接踵而至，例如Alpaca、BOOLM、LLaMA、ChatGLM、<code>DeepSpeed</code>Chat、ColossalChat等。不论是学术界还是工业界，都有训练大模型来优化下游任务的需求。</p>
<p>然而，大量实验证明，在高质量的训练语料进行指令微调（<code>Instruction-tuning</code>）的前提下， <strong>超过百亿参数量的模型才具备一定的涌现能力</strong> ，尤其是在一些复杂的推理任务上，例如下图：</p>
<img src="/post/nlp007/1.jpg" class title="图片">
<blockquote>
<ul>
<li>图来自论文<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.11903.pdf">《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》</a></li>
</ul>
</blockquote>
<p>也就是说，如果我们需要通过大模型技术来提升业务指标，不得不要求我们去训练一个百亿规模的模型。</p>
<p>然而，一般情况下，我们不具备如此大规模的计算资源，尤其是对于学校里一般的科研团队，也许只有少量V100（32G），运气好可能会有几台A100。因此在有限的算力条件下训练或推理一个百亿量级的大模型是不太现实的。因此，无疑要在训练和推理两个阶段采用一些优化策略来解决此类问题。</p>
<p>本篇博文主要整理一系列大模型在训练和推理两个阶段的优化技术，以满足我们在有限的计算资源的条件下训练自己的大模型，下面列出本文主要介绍的一些优化技术：</p>
<ul>
<li><p><a href="#二、混合精度训练"><strong>二、混合精度训练</strong></a>：FP16+FP32 或 BF16+FP32；</p>
</li>
<li><p><a href="#三、&lt;code&gt;DeepSpeed&lt;/code&gt;分布式训练"><strong>三、<code>DeepSpeed</code>分布式训练</strong></a>：<code>ZeRO-1</code>、<code>ZeRO-2</code>、<code>ZeRO-3</code>；</p>
</li>
<li><p><a href="#四、Torch"><strong>四、Torch <code>FSDP</code> + CPU Offloading</strong></a>；</p>
</li>
<li><p><a href="#五、&lt;code&gt;3D并行&lt;/code"><strong>五、<code>3D并行</code></strong></a> ；</p>
</li>
<li><p><a href="#六、&lt;code&gt;INT8量化&lt;/code"><strong>六、<code>INT8模型量化</code></strong></a> ：对称/非对称量化、量化感知训练；</p>
</li>
<li><p><a href="#七、PEFT"><strong>七、PEFT（Parameter-Efficient Learning）</strong></a> ：<code>LoRA</code>、<code>Adapter</code>、<code>BitFit</code>、<code>P-tuning</code>；</p>
</li>
<li><p><a href="#八、混合专家训练"><strong>八、混合专家训练（<code>Mixed-of Experts</code>，<code>MoE</code>）</strong></a> ：每次只对部分参数进行训练；</p>
</li>
<li><p><a href="#九、梯度累积"><strong>九、梯度累积（<code>Gradient Accumulation</code>）</strong></a> ：时间换空间</p>
</li>
<li><p><a href="#十、梯度检查点"><strong>十、梯度检查点（Gradient checkpointing）</strong></a> ：时间换空间</p>
</li>
<li><p><a href="#十一、&lt;code&gt;FlashAttention&lt;/code"><strong>十一、<code>Flash Attention</code></strong></a></p>
</li>
<li><p><a href="#参考资料"><strong>参考资料</strong></a></p>
</li>
</ul>
<h2 id="一、Transformer模型算力评估"><a href="#一、Transformer模型算力评估" class="headerlink" title="一、Transformer模型算力评估"></a>一、<code>Transformer</code>模型算力评估</h2><p>在介绍优化技术之前，首先介绍一下如何评估大模型的算力。众所周知，现如今的预训练语言模型均是基于<code>Transformer</code>结构实现的，因此大模型的参数主要来源于<code>Transformer</code>的<code>Self-Attention</code>部分。EleutherAI团队近期发布一篇博客来介绍如何估计一个大模型的算力成本，公式如下：<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="15.22ex" height="1.781ex" role="img" focusable="false" viewbox="0 -705 6727.1 787" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-2-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/><path id="MJX-2-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/><path id="MJX-2-TEX-I-1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"/><path id="MJX-2-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"/><path id="MJX-2-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"/><path id="MJX-2-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"/><path id="MJX-2-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/><path id="MJX-2-TEX-I-1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-2-TEX-I-1D436"/></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="3D" xlink:href="#MJX-2-TEX-N-3D"/></g><g data-mml-node="mi" transform="translate(2093.6,0)"><use data-c="1D70F" xlink:href="#MJX-2-TEX-I-1D70F"/></g><g data-mml-node="mi" transform="translate(2610.6,0)"><use data-c="1D447" xlink:href="#MJX-2-TEX-I-1D447"/></g><g data-mml-node="mo" transform="translate(3592.3,0)"><use data-c="2248" xlink:href="#MJX-2-TEX-N-2248"/></g><g data-mml-node="mn" transform="translate(4648.1,0)"><use data-c="36" xlink:href="#MJX-2-TEX-N-36"/></g><g data-mml-node="mi" transform="translate(5148.1,0)"><use data-c="1D443" xlink:href="#MJX-2-TEX-I-1D443"/></g><g data-mml-node="mi" transform="translate(5899.1,0)"><use data-c="1D437" xlink:href="#MJX-2-TEX-I-1D437"/></g></g></g></g></svg></mjx-container></p>
<blockquote>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewbox="0 -705 760 727" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-2-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-2-TEX-I-1D436"/></g></g></g></g></svg></mjx-container>表示<code>Transformer</code>需要的计算量，单位是<code>FLOP</code>；<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.699ex" height="1.545ex" role="img" focusable="false" viewbox="0 -683 751 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"/></g></g></g></g></svg></mjx-container>表示<code>Transformer</code>模型包含的参数量；<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.873ex" height="1.545ex" role="img" focusable="false" viewbox="0 -683 828 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D437" xlink:href="#MJX-1-TEX-I-1D437"/></g></g></g></g></svg></mjx-container>表示训练数据规模，以<code>Token</code>数量为单位；<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.029ex;" xmlns="http://www.w3.org/2000/svg" width="1.17ex" height="1.005ex" role="img" focusable="false" viewbox="0 -431 517 444" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D70F" xlink:href="#MJX-1-TEX-I-1D70F"/></g></g></g></g></svg></mjx-container>表示吞吐量，单位为<code>FLOP</code><br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewbox="0 -677 704 677" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-1-TEX-I-1D447"/></g></g></g></g></svg></mjx-container>表示训练时间；</p>
</blockquote>
<p>该公式的原理如下：</p>
<blockquote>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="30.938ex" height="1.952ex" role="img" focusable="false" viewbox="0 -705 13674.5 862.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/><path id="MJX-1-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"/><path id="MJX-1-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"/><path id="MJX-1-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path id="MJX-1-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"/><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"/><path id="MJX-1-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path id="MJX-1-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/><path id="MJX-1-TEX-N-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"/><path id="MJX-1-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"/><path id="MJX-1-TEX-N-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"/><path id="MJX-1-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"/><path id="MJX-1-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"/><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/><path id="MJX-1-TEX-I-1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"/></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"/></g><g data-mml-node="msub" transform="translate(2093.6,0)"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"/></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-1-TEX-N-66"/><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(306,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(806,0)"/><use data-c="77" xlink:href="#MJX-1-TEX-N-77" transform="translate(1198,0)"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(1920,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(2420,0)"/><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(2812,0)"/></g></g></g><g data-mml-node="mo" transform="translate(5495.3,0)"><use data-c="2B" xlink:href="#MJX-1-TEX-N-2B"/></g><g data-mml-node="msub" transform="translate(6495.5,0)"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"/></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="62" xlink:href="#MJX-1-TEX-N-62"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(556,0)"/><use data-c="63" xlink:href="#MJX-1-TEX-N-63" transform="translate(1056,0)"/><use data-c="6B" xlink:href="#MJX-1-TEX-N-6B" transform="translate(1500,0)"/><use data-c="77" xlink:href="#MJX-1-TEX-N-77" transform="translate(2028,0)"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(2750,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(3250,0)"/><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(3642,0)"/></g></g></g><g data-mml-node="mo" transform="translate(10539.7,0)"><use data-c="2248" xlink:href="#MJX-1-TEX-N-2248"/></g><g data-mml-node="mn" transform="translate(11595.5,0)"><use data-c="36" xlink:href="#MJX-1-TEX-N-36"/></g><g data-mml-node="mi" transform="translate(12095.5,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"/></g><g data-mml-node="mi" transform="translate(12846.5,0)"><use data-c="1D437" xlink:href="#MJX-1-TEX-I-1D437"/></g></g></g></g></svg></mjx-container>：表示训练过程中的前后向传播；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="14.914ex" height="1.952ex" role="img" focusable="false" viewbox="0 -705 6592.1 862.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/><path id="MJX-1-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"/><path id="MJX-1-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"/><path id="MJX-1-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path id="MJX-1-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"/><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"/><path id="MJX-1-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path id="MJX-1-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"/><path id="MJX-1-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/><path id="MJX-1-TEX-I-1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"/></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-1-TEX-N-66"/><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(306,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(806,0)"/><use data-c="77" xlink:href="#MJX-1-TEX-N-77" transform="translate(1198,0)"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(1920,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(2420,0)"/><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(2812,0)"/></g></g></g><g data-mml-node="mo" transform="translate(3457.3,0)"><use data-c="2248" xlink:href="#MJX-1-TEX-N-2248"/></g><g data-mml-node="mn" transform="translate(4513.1,0)"><use data-c="32" xlink:href="#MJX-1-TEX-N-32"/></g><g data-mml-node="mi" transform="translate(5013.1,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"/></g><g data-mml-node="mi" transform="translate(5764.1,0)"><use data-c="1D437" xlink:href="#MJX-1-TEX-I-1D437"/></g></g></g></g></svg></mjx-container>：前向传播计算成本约等于两倍的参数量乘以数据规模；</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="16.242ex" height="1.952ex" role="img" focusable="false" viewbox="0 -705 7179 862.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/><path id="MJX-1-TEX-N-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"/><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"/><path id="MJX-1-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"/><path id="MJX-1-TEX-N-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"/><path id="MJX-1-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"/><path id="MJX-1-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path id="MJX-1-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path id="MJX-1-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"/><path id="MJX-1-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"/><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/><path id="MJX-1-TEX-I-1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"/></g><g data-mml-node="TeXAtom" transform="translate(748,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="62" xlink:href="#MJX-1-TEX-N-62"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(556,0)"/><use data-c="63" xlink:href="#MJX-1-TEX-N-63" transform="translate(1056,0)"/><use data-c="6B" xlink:href="#MJX-1-TEX-N-6B" transform="translate(1500,0)"/><use data-c="77" xlink:href="#MJX-1-TEX-N-77" transform="translate(2028,0)"/><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(2750,0)"/><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(3250,0)"/><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(3642,0)"/></g></g></g><g data-mml-node="mo" transform="translate(4044.2,0)"><use data-c="2248" xlink:href="#MJX-1-TEX-N-2248"/></g><g data-mml-node="mn" transform="translate(5100,0)"><use data-c="34" xlink:href="#MJX-1-TEX-N-34"/></g><g data-mml-node="mi" transform="translate(5600,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"/></g><g data-mml-node="mi" transform="translate(6351,0)"><use data-c="1D437" xlink:href="#MJX-1-TEX-I-1D437"/></g></g></g></g></svg></mjx-container>：反向传播计算成本约等于四倍的参数量乘以数据规模；</li>
</ul>
<p>是一个量化计算成本的单位，通常用<code>FLOP</code>表示，我们也可以用一些新的单位来表示：</p>
<ul>
<li><p><code>FLOP/s-s</code>：表示每秒浮点运算数×秒；</p>
</li>
<li><p>Peta<code>FLOP/s-days</code>：表示实际情况下每秒浮点运算数×天。</p>
</li>
</ul>
</blockquote>
<p>下图展示了不同规模的预训练语言模型的算力成本：</p>
<img src="/post/nlp007/2.jpg" class title="图片">
<p>可知，随着规模的增大，其算力成本会呈现指数级别的增长。</p>
<blockquote>
<p>参见原文：<a target="_blank" rel="noopener" href="https://blog.eleuther.ai/transformer-math/">https://blog.eleuther.ai/transformer-math/</a><sup>[1]</sup></p>
</blockquote>
<h2 id="二、混合精度训练"><a href="#二、混合精度训练" class="headerlink" title="二、混合精度训练"></a>二、混合精度训练</h2><p>混合精度训练是一个很常用的显存优化技术，其适用于单机单卡或多卡并行场景。一般情况下，计算机在进行浮点运算时所采用的是FP32（单精度），其中8位用于存储整数部分，23位存储小数部分，因此其可以存储高精度浮点数。</p>
<p>因此在显存优化场景下，牺牲浮点运算的精度可以降低存储量。<br>采用FP16进行浮点运算时，只需要一半的存储空间即可，因此成为半精度浮点运算。但是FP16的整数为只能最大到65536，很容易出现溢出问题。<br>BF16是另一种半精度浮点运算表示，其相较于FP16来说，增大了整数部分的存储位，避免计算溢出问题，但是也牺牲了一定的精度。<br><img src="/post/nlp007/3.1.png" class title="图片"><br><img src="/post/nlp007/3.jpg" class title="图片"><br><mark>注：S是符号位、E是阶码、M是数值/尾数位</mark><br><mark>阶码决定范围，数值位决定精度</mark><br>在实际的训练时，通常是将单精度与半精度进行混合实现浮点运算的。典型代表是<code> <strong>动态混合精度法（Automatic Mixed Precision，AMP）</strong> </code>，如下图所示：</p>
<img src="/post/nlp007/4.jpg" class title="图片">
<ul>
<li><p>O0：表示最原始的FP32浮点运算；</p>
</li>
<li><p>O1：除了优化器部分为FP32，其余都使用FP16；</p>
</li>
<li><p>O2：在O1的基础上，额外使用FP32保存了一份参数用于参数更新；</p>
</li>
<li><p>O3：所有参数全部为半精度；</p>
</li>
</ul>
<p><code>AMP</code>采用的是混合FP32+FP16，在不同的训练阶段动态地指定那些部分转换为半精度进行训练。<code>AMP</code>典型的是使用上图的O2部分</p>
<ul>
<li><blockquote>
<p>混合精度训练优点：<br>1、可以提高乘法运算过程中的效率<br>2、效避免累加时的舍入误差问题。</p>
</blockquote>
</li>
</ul>
<p>Pytorch1.5版本后继承了<code>AMP</code>的实现，调用<code>AMP</code>进行混合精度训练的例子如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.cuda.AMP <span class="keyword">import</span> autocast, GradScaler</span><br><span class="line"><span class="comment"># FP32模型</span></span><br><span class="line">model = Net().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), ...)</span><br><span class="line">scaler = GradScaler()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epoches:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">with</span> autocast():</span><br><span class="line">            output = model(<span class="built_in">input</span>)</span><br><span class="line">            loss = loss_fn(output, target)</span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line">        scaler.step(optimizer)</span><br><span class="line">        scale.update()</span><br></pre></td></tr></table></figure>
<h2 id="三、DeepSpeed分布式训练"><a href="#三、DeepSpeed分布式训练" class="headerlink" title="三、DeepSpeed分布式训练"></a>三、<code>DeepSpeed</code>分布式训练</h2><p>一张32G的GPU上可能无法塞得下100亿模型的权重、梯度、优化器等参数，但是我们或许可以将这些参数按照一定规则拆分到多张卡上，这便是分布式并行优化的思想。</p>
<p><code>DeepSpeed</code>是由微软开源的分布式训练加速框架，其使用了一种称为零冗余（<code>ZeRO</code>）的显存优化技术。本质上，它是一种 <mark><strong>数据并行</strong></mark> 的分布式训练策略，重点<code>优化了数据并行中的显存占用问题</code>。在<code>ZeRO</code>数据并行中，<mark>每个GPU上虽然拥有完整的网络，但是每个GPU只保存一部分的权重，梯度和优化器状态信息，这样就就可以将权重，梯度，优化器状态信息平均分配到多个GPU上。</mark></p>
<p>下图展示了<code>DeepSpeed</code>的3种<code>ZeRO stage</code>。假设需要训练的模型占用显存位120G，集群内有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex;" xmlns="http://www.w3.org/2000/svg" width="2.836ex" height="1.901ex" role="img" focusable="false" viewbox="0 -683 1253.7 840.1" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"/><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D441" xlink:href="#MJX-1-TEX-I-1D441"/></g><g data-mml-node="mi" transform="translate(836,-150) scale(0.707)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g></g></g></g></g></svg></mjx-container>张GPU：</p>
<img src="/post/nlp007/5.jpg" class title="图片">
<ul>
<li><p><strong><code>Baseline</code></strong> ：传统的数据并行策略，每张GPU上存储全部模型的权重、梯度和优化器等参数，每张卡上并行训练不同的数据，并实现参数汇聚更新。该情况下，每张卡依然要加载120G参数，显然是无法在一般机器上实现的；</p>
</li>
<li><p><strong><code>ZeRO Stage1</code></strong> ——<mark style="background-color:red">优化器并行</mark>：在训练过程中，优化器状态参数占用的显存空间是非常大的，因此将优化器状态参数分发到不同的GPU上，此时单张卡上的显存占用会大大降低；</p>
</li>
<li><p><strong><code>ZeRO Stage2</code></strong> ——<mark style="background-color:red">梯度+优化器并行</mark>：在<code>ZeRO Stage1</code>的基础上，额外对梯度进行了分布式存储，可以发现120G的显存占用直接降低到16G；</p>
</li>
<li><p><strong><code>ZeRO Stage3</code></strong> ——<mark style="background-color:red">权重+梯度+优化器并行</mark>：模型的所有参数都进行分布式存储，此时一张卡上只有1.9G占用。</p>
</li>
</ul>
<p>基于<code>ZeRO</code>在训练过程中的原理，有博主分享比较精妙的图，来源于<a target="_blank" rel="noopener" href="https://blog.csdn.net/cjnewstar111/article/details/128593120">多图，秒懂 如何训练一个“万亿大模型”？</a><sup>[2]</sup>。假设有2张卡，训练一个2层的<code>Transformer</code>模型：</p>
<h3 id="（1）传统的数据并行"><a href="#（1）传统的数据并行" class="headerlink" title="（1）传统的数据并行"></a>（1）传统的数据并行</h3><p>每张卡上都完整的存放模型全部参数（橘黄色部分），包括权重、梯度和优化器。在前向传播过程中，每张卡上独立地对喂入的数据进行计算，逐层获得激活值（<code>Transformer</code>模型中的<code>FeedForward</code>模块的输出）：</p>
<img src="/post/nlp007/6.jpg" class title="图片">
<p>计算梯度时，每个卡上的模型，每个参数都单独计算梯度，并存储下来（紫色部分）：</p>
<img src="/post/nlp007/7.jpg" class title="图片">
<p><mark>在梯度更新阶段，对所有卡上的梯度进行平均处理，然后各张卡独立地进行梯度更新，并保存当前的优化器状态信息（浅蓝色部分）<mark>：</mark></mark></p>
<img src="/post/nlp007/8.jpg" class title="图片">
<h3 id="（2）DeepSpeed-ZeRO-并行训练"><a href="#（2）DeepSpeed-ZeRO-并行训练" class="headerlink" title="（2）DeepSpeed ZeRO 并行训练"></a>（2）<code>DeepSpeed ZeRO</code> 并行训练</h3><p><code>DeepSpeed</code>则是在数据并行的基础上，对权重、梯度和优化器状态也进行了分布式存储，下面几张图展示<code>ZeRO Stage3</code>的情况。在初始时，假设两张卡分别只存储一层<code>Transformer</code>。当某一张卡在进行前向传播时，如果此时参数不存在，则需要朝有该参数的卡上借用该参数进行前向计算。例如在GPU1上计算第2层<code>Transformer</code>时，需要GPU2上的参数拷贝给GPU1实现第2层<code>Transformer</code>的计算。</p>
<blockquote>
<p>这也是为什么在使用ZeRO的时候，GPU的显存会不断变化。</p>
</blockquote>
<img src="/post/nlp007/9.jpg" class title="图片">
<p><mark>前向传播结束后，需要进行梯度计算。例如GPU2需要保存w2对应的梯度g2，因此所有其他GPU将g2梯度发送给GPU2。GPU2上面得到各个GPU的g2梯度后，做规约操作并保存，得到g2~。其他GPU将会删除w2，g2。然后重复该流程，直到所有layer都完成反向传播计算：<mark></mark></mark></p>
<img src="/post/nlp007/10.jpg" class title="图片">
<p>参数更新时，直接单独进行更新即可：</p>
<img src="/post/nlp007/11.jpg" class title="图片">
<p>目前<code>HuggingFace</code>的<code>Transformers</code>库已经集成了<code>DeepSpeed</code>框架，只需要配置<code>ZeRO</code>文件即可，下面列出博主常用的一些配置：</p>
<p>（1）<code>ZeRO Stage1</code>:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;zero_optimization&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;stage&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cpu_offload&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fp16&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;steps_per_print&quot;</span><span class="punctuation">:</span> <span class="number">1000</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>（2）<code>ZeRO Stage2</code>:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;zero_optimization&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">     <span class="attr">&quot;stage&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fp16&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;loss_scale&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;loss_scale_window&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;initial_scale_power&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hysteresis&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;min_loss_scale&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;steps_per_print&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AdamW&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;lr&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;betas&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;weight_decay&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>（3）<code>ZeRO Stage3</code>:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;fp16&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;loss_scale&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;loss_scale_window&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;initial_scale_power&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;hysteresis&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;min_loss_scale&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;bf16&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AdamW&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;lr&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;betas&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;weight_decay&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;zero_optimization&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;stage&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;offload_optimizer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;device&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cpu&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;pin_memory&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;offload_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;device&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cpu&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;pin_memory&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;overlap_comm&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;contiguous_gradients&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sub_group_size&quot;</span><span class="punctuation">:</span> <span class="number">1e9</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;reduce_bucket_size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;stage3_prefetch_bucket_size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;stage3_param_persistence_threshold&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;stage3_max_live_parameters&quot;</span><span class="punctuation">:</span> <span class="number">1e9</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;stage3_max_reuse_distance&quot;</span><span class="punctuation">:</span> <span class="number">1e9</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;gradient_clipping&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;steps_per_print&quot;</span><span class="punctuation">:</span> <span class="number">2000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;train_batch_size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="punctuation">:</span> <span class="string">&quot;auto&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;wall_clock_breakdown&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>基于<code>HuggingFace</code>的<code>Transformer</code>库在使用时，可直接指定配置文件即可，例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--deepSpeed=./ds_config_fp16_z1.json</span><br></pre></td></tr></table></figure></p>
<h2 id="四、Torch-FSDP-CPU-Offloading"><a href="#四、Torch-FSDP-CPU-Offloading" class="headerlink" title="四、Torch FSDP + CPU Offloading"></a>四、Torch FSDP + CPU Offloading</h2><p><code>Fully Sharded Data Paralle</code>（<code>FSDP</code>）和 <code>DeepSpeed</code> 类似，均通过 <code>ZeRO</code> 等分布优化算法，减少内存的占用量。其将 <mark>模型参数、梯度和优化器状态<mark> 分布至多个 GPU 上，而非像传统的分布式训练在每个GPU上保留完整副本。</mark></mark></p>
<p><code>CPU offload</code> 则允许在一个 <code>back propagation</code> 中，将参数动态地在GPU和CPU之间相互转移，从而节省GPU显存。</p>
<blockquote>
<p><code>HuggingFace</code> 这篇博文解释了 <a target="_blank" rel="noopener" href="https://HuggingFace.co/blog/zero-DeepSpeed-fairscale"><code>ZeRO</code> 的大致实现方法</a><sup>[3]</sup></p>
<p>借助 torch 实现 <code>FSDP</code>，只需要将 model 用 <code>FSDP</code>warp 一下；同样，cpu_offload 也只需要一行代码：<a target="_blank" rel="noopener" href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/</a><sup>[4]</sup><br>在这个可以查看 <code>FSDP</code> <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/FSDP.html">支持的模型</a><sup>[5]</sup><br>在 <code>HuggingFace Transformers</code> 中使用 <a target="_blank" rel="noopener" href="https://HuggingFace.co/docs/Transformers/v4.27.2/en/main\_classes/trainer#Transformers.Trainin"><code>Torch FSDP</code></a><sup>[6]</sup></p>
</blockquote>
<h2 id="五、3D并行"><a href="#五、3D并行" class="headerlink" title="五、3D并行"></a>五、<code>3D并行</code></h2><p>上述讲到的<code>DeepSpeed</code>、<code>FSDP</code>等都是数据并行，事实上也有模型并行以及流水线并行。关于<code>3D并行</code>的方法可参考文献：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/617087561">一文捋顺千亿模型训练技术：流水线并行、张量并行和3D并行</a><sup>[7]</sup></p>
<h2 id="六、INT8量化"><a href="#六、INT8量化" class="headerlink" title="六、INT8量化"></a>六、<code>INT8量化</code></h2><p>深度学习模型量化是一个面向模型参数的显存优化技术，<mark>与FP16比较类似，都是为了损失一些精度来降低空间</mark>。<br>但不同于FP16的是，<mark><code>INT8量化</code>是一种间接的精度转换方法</mark>。在介绍<code>INT8量化</code>之前，需要引入一些基本概念：</p>
<ul>
<li><p><strong>定点数</strong> ：常用的定点数有两种表示形式：如果小数点位置约定在最低数值位的后面，则该数只能是定点整数；如果小数点位置约定在最高数值位的前面，则该数只能是定点小数。</p>
</li>
<li><p><strong>浮点数</strong> ：在存储时，一个浮点数所占用的存储空间被划分为两部分，分别存放尾数和阶码。尾数部分通常使用定点小数方式，阶码则采用定点整数方式。尾数的长度影响该数的精度，而阶码则决定该数的表示范围。</p>
</li>
</ul>
<blockquote>
<p>为了节省内存，计算机中数值型数据的小数点的位置是隐含的，且小数点的位置既可以是固定的，也可以是变化的。如果小数点的位置事先已有约定，不再改变，此类数称为“定点数”。相比之下，如果小数点的位置可变，则称为“浮点数”。</p>
</blockquote>
<h3 id="对称量化（Scale-Quantization）"><a href="#对称量化（Scale-Quantization）" class="headerlink" title="对称量化（Scale Quantization）"></a>对称量化（Scale Quantization）</h3><p>这里我们用 表示浮点实数，以及最大最小值 ， 表示量化后的定点整数，其最大最小值为 （在INT8中，最大最小值为-128， 127）， 表示量化因子（scale），即由浮点数到整型数的比例， 表示浮点数中0对应量化后的整型数。当 时，则为对称量化，此时则有：</p>
<p>因为是对称量化，所以浮点数0对应的定点整型数也是0，即：</p>
<p>则对于浮点数 ，其量化后的结果是 ；对于一个整型数，其反量化后的结果是 。</p>
<p>对称量化的优缺点：</p>
<ul>
<li><p>优势：推理速度快，量化方式简单；</p>
</li>
<li><p>缺点：对于一些特殊的值（例如激活函数后的值），往往均大于0，此时会浪费掉INT8的一些空间，使得量化后的结果不均匀。</p>
</li>
</ul>
<h3 id="非对称量化（Affine-Quantization）"><a href="#非对称量化（Affine-Quantization）" class="headerlink" title="非对称量化（Affine Quantization）"></a>非对称量化（Affine Quantization）</h3><p>这里我们用 表示浮点实数，以及最大最小值 ， 表示量化后的定点整数，其最大最小值为 （在INT8中，最大最小值为-128， 127）， 表示量化因子（scale），即由浮点数到整型数的比例， 表示浮点数中0对应量化后的整型数。因此有：</p>
<p>对于浮点数 ，其量化后的结果是 ；对于一个整型数，其反量化后的结果是 。</p>
<blockquote>
<p>量化过程中，由于存在round算子，因此会造成精度损失，但是反量化不会造成精度损失；浮点数0不存在精度损失。</p>
</blockquote>
<p><strong>（1）Absmax Quantization（最大量化）</strong> 该方法的一个典型的是absmax quantization技术。将一个FP32（单精度4字节）的float类型数据转换为INT8。由于INT8只有-127～127，因此可以通过对FP32值乘以一个量化因子，将浮点数转换为整型数。如下所示：</p>
<img src="/post/nlp007/12.jpg" class title="图片">
<blockquote>
<p>给定一个数组，首先找到该数组中的最大值5.4，然后计算127/5.4=23.5，因此量化因子则为23.5（相当于当前浮点数中最大值放大至-127～127区间内的最大值）。数组中的数乘以量化因子得到的值进行四舍五入估计，即可得到整型数组。解码时，则将整型数除以量化因子即可。由于期间进行了四舍五入估计，因此量化时会有损失。</p>
</blockquote>
<img src="/post/nlp007/13.jpg" class title="图片">
<p><strong>（2）基于threshold的量化（量化裁剪）</strong> 在浮点数范围内，设置两个阈值，记作 和 （），因此当给定一个浮点数 时，可以定义一个裁剪函数：<br><img src="/post/nlp007/14.jpg" class title="图片"></p>
<p>只保留在区间 范围内的浮点数，其余的则抛弃。该方法又称为饱和量化，由于通过阈值去掉了一些不重要的元素，可以有效解决不均匀问题。</p>
<img src="/post/nlp007/15.jpg" class title="图片">
<blockquote>
<p>当浮点数的分布均匀时，absmax量化精度损失较小。但当浮点数分布不均匀时，按照最大最小值映射，则实际有效的int8动态范围就更小了，精度损失变大。因此，如果将最大值换为阈值，即超出阈值的部分舍去，在阈值范围内的进行量化，可以降低精度误差。</p>
</blockquote>
<p>因此核心的问题是 <strong>如何寻找最优的阀值T使得精度的损失最小</strong> 。通过实验发现，在range和precision之间的trade-off关系如下图所示：</p>
<img src="/post/nlp007/16.jpg" class title="图片">
<p>NVIDIA选择的是 <strong>KL-divergence</strong> 实现量化校准，其实就是相对熵，那为什么要选择相对熵呢？而不是其他的别的什么呢？因为 <strong>相对熵表述的就是两个分布的差异程度</strong> ，放到我们的情境里面来就是 <strong><code>INT8量化</code>前后两个分布的差异程度</strong> ，差异最小就是最好的了。因此问题转换为求相对熵的最小值！</p>
<p>NVIDIA的量化校准流程如下：</p>
<ul>
<li><p>收集激活值的直方图；</p>
</li>
<li><p>基于不同的阀址产生不同的量化分布；</p>
</li>
<li><p>然后计算每个分布与原分布的相对熵，然后选择KL散度最小的一个。</p>
</li>
</ul>
<h3 id="量化感知训练（Quantization-aware-Training）"><a href="#量化感知训练（Quantization-aware-Training）" class="headerlink" title="量化感知训练（Quantization-aware Training）"></a>量化感知训练（Quantization-aware Training）</h3><p>上述讲到的是模型推理过程中使用<code>INT8量化</code>，可以加速推理速度。INT8依然也可以用在训练过程中。在训练过程中引入伪量化的操作，用于模拟量化过程带来的误差（这一框架无论在resnet这种大模型，还是mobilenet这种本身比较精简的网络上效果都不错）。</p>
<img src="/post/nlp007/17.jpg" class title="图片">
<p><strong>伪量化</strong> 是指将模拟量化操作引入训练过程中，如上图（b)，在每个weight的输入后与output的输出前进行伪量化，将浮点量化到定点整型数，再反量化成浮点，用round过程中所产生的误差的浮点值进行前向运算。</p>
<ul>
<li><p>伪量化的操作可以使权值、激活值的分布更加均匀，也就是方差更小；</p>
</li>
<li><p>相比直接进行后量化的精度损失能更小；</p>
</li>
<li><p>能够控制每层的输出在一定范围内，对溢出处理更有帮助；</p>
</li>
<li><p>值得注意的是，量化训练中都是采用浮点运算来模拟定点运算，所以训练过程中的量化结果与真实量化结果是有差异的。</p>
</li>
</ul>
<blockquote>
<p>相关文献：<br>量化 | 深度学习Int8的部署推理原理和经验验证<sup>[8]</sup><br><code>INT8量化</code>-介绍（一）<sup>[9]</sup><br>其他常用的量化方法：</p>
<ul>
<li><p>PACT：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.06085v2">https://arxiv.org/abs/1805.06085v2</a></p>
</li>
<li><p>Dorefa：(PDF) DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients (researchgate.netL</p>
</li>
<li><p>LSQ：Learned Step Size Quantization</p>
</li>
<li><p>LSQ+：LSQ+: Improving low-bit quantization through learnable offsets and better initialization</p>
</li>
</ul>
<p>类ChatGPT模型量化：</p>
<ul>
<li><p>GPTQ算法</p>
</li>
<li><p>GPTQ-for-LLaMa</p>
</li>
</ul>
</blockquote>
<h2 id="七、PEFT"><a href="#七、PEFT" class="headerlink" title="七、PEFT"></a>七、PEFT</h2><p>针对参数层面上的优化还有参数有效性学习（Parameter-Efficient Learning，PEL）。参数有效性学习旨 <strong>在训练过程中指定少量参数参与梯度的计算和更新</strong> ，从而在梯度和优化器参数上降低显存占用。</p>
<p>参数有效性学习有很多经典的方法，比如<code>Adapter</code>-tuning、Prefix-tuning、<code>P-tuning</code>、<code>LoRA</code>、<code>BitFit</code>等。本部分主要介绍<code>LoRA</code>方法，因为在很多类ChatGPT的训练中都采用<code>LoRA</code>进行参数有效性训练。</p>
<img src="/post/nlp007/18.jpg" class title="图片">
<p>如上图所示，蓝色部分为原始的模型参数，其将输入<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 572 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-1-TEX-I-1D465"/></g></g></g></g></svg></mjx-container>通过一个FC层映射到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.303ex" height="1.595ex" role="img" focusable="false" viewbox="0 -694 576 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-1-TEX-I-210E"/></g></g></g></g></svg></mjx-container>。然而矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex;" xmlns="http://www.w3.org/2000/svg" width="9.867ex" height="2.022ex" role="img" focusable="false" viewbox="0 -853.7 4361.1 893.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/><path id="MJX-1-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/><path id="MJX-1-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"/><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/><path id="MJX-1-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D44A" xlink:href="#MJX-1-TEX-I-1D44A"/></g><g data-mml-node="mo" transform="translate(1325.8,0)"><use data-c="2208" xlink:href="#MJX-1-TEX-N-2208"/></g><g data-mml-node="msup" transform="translate(2270.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-1-TEX-D-211D"/></g></g><g data-mml-node="TeXAtom" transform="translate(755,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g><g data-mml-node="mo" transform="translate(520,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-N-D7"/></g><g data-mml-node="mi" transform="translate(1298,0)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g></g></g></g></g></g></svg></mjx-container>的训练参数量为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="4.113ex" height="1.593ex" role="img" focusable="false" viewbox="0 -694 1818 704" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/><path id="MJX-1-TEX-I-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g><g data-mml-node="mi" transform="translate(520,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-I-D7"/></g><g data-mml-node="mi" transform="translate(1298,0)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g></g></g></g></svg></mjx-container>。通过添加一个<code>LoRA</code>层（红色部分），将输入<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 572 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-1-TEX-I-1D465"/></g></g></g></svg></mjx-container>先映射到低纬度空间，再映射回 维度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewbox="0 -694 520 704" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g></g></g></svg></mjx-container>，此时需要的参数量只有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="5.088ex" height="1.595ex" role="img" focusable="false" viewbox="0 -694 2249 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/><path id="MJX-1-TEX-I-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/><path id="MJX-1-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="32" xlink:href="#MJX-1-TEX-N-32"/></g><g data-mml-node="mi" transform="translate(500,0)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"/></g><g data-mml-node="mi" transform="translate(1020,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-I-D7"/></g><g data-mml-node="mi" transform="translate(1798,0)"><use data-c="1D45F" xlink:href="#MJX-1-TEX-I-1D45F"/></g></g></g></svg></mjx-container>，其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.02ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 451 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D45F" xlink:href="#MJX-1-TEX-I-1D45F"/></g></g></g></g></svg></mjx-container>为<code>LoRA</code>的秩。在训练时，<mark>只需要对红色部分的参数进行训练和梯度计算保存</mark>，因此大大降低了训练过程中的开销。</p>
<blockquote>
<p>-引入<code>LoRA</code>部分的参数，并不会在推理阶段加速，因为在前向计算的时候，红色部分的参数还是需要参与计算的，因此<mark>推理阶段应该比原来的计算量增大一点</mark>。</p>
</blockquote>
<p>接下来给出采用<code>LoRA</code>进行训练的案例，例如选择<code>OPT-6.7B</code>模型进行参数有效性训练时，可以借助<code>HuggingFace <strong>PEFT</strong></code>  库实现：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/huggingface/peft/blob/main/examples/int8_training/Finetune_opt_bnb_peft.ipynb">Finetune_opt_bnb_peft</a><sup>[10]</sup></p>
</blockquote>
<p>使用<code>PEFT</code>库进行训练代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> bitsandbytes <span class="keyword">as</span> bnb</span><br><span class="line"><span class="keyword">import</span> Transformers</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> Transformers <span class="keyword">import</span> AutoTokenizer, AutoConfig, AutoModelForCausalLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> prepare_model_for_int8_training, LoRAConfig, get_peft_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正常地加载大模型参数</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;facebook/opt-6.7b&quot;</span>,</span><br><span class="line">    load_in_8bit=<span class="literal">True</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 加载Tokenizer</span></span><br><span class="line">Tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;facebook/opt-6.7b&quot;</span>)</span><br><span class="line"><span class="comment"># 将大模型参数进行INT8量化</span></span><br><span class="line">model = prepare_model_for_int8_training(model)</span><br><span class="line"><span class="comment"># 配置Parameter-efficient LoRA</span></span><br><span class="line">config = LoRAConfig(</span><br><span class="line">    r=<span class="number">16</span>, </span><br><span class="line">    LoRA_alpha=<span class="number">32</span>, </span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>], </span><br><span class="line">    LoRA_dropout=<span class="number">0.05</span>, bias=<span class="string">&quot;none&quot;</span>, </span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 获得增加LoRA的新模型</span></span><br><span class="line">model = get_peft_model(model, config)</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = load_dataset(<span class="string">&quot;Abirate/english_quotes&quot;</span>)</span><br><span class="line">data = data.<span class="built_in">map</span>(<span class="keyword">lambda</span> sAMPles: Tokenizer(sAMPles[<span class="string">&quot;quote&quot;</span>]), batched=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 获得Trainer</span></span><br><span class="line">trainer = Transformers.Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    train_dataset=data[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    args=Transformers.TrainingArguments(</span><br><span class="line">        per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">        gradient_accumulation_steps=<span class="number">4</span>,</span><br><span class="line">        warmup_steps=<span class="number">100</span>,</span><br><span class="line">        max_steps=<span class="number">200</span>,</span><br><span class="line">        learning_rate=<span class="number">2e-4</span>,</span><br><span class="line">        fp16=<span class="literal">True</span>,</span><br><span class="line">        logging_steps=<span class="number">1</span>,</span><br><span class="line">        output_dir=<span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">    data_collator=Transformers.DataCollatorForLanguageModeling(Tokenizer, mlm=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model.config.use_cache = <span class="literal">False</span>  <span class="comment"># silence the warnings. Please re-enable for inference!</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<p><code>LoRA</code>涉及到如下一些配置：</p>
<img src="/post/nlp007/19.jpg" class title="图片">
<p>在推理阶段，只需要加载<code>LoRA</code>的参数，并集成到原始的<code>OPT-6.7B</code>模型中即可，实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel, PeftConfig</span><br><span class="line"><span class="keyword">from</span> Transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">peft_model_id = <span class="string">&quot;ybelkada/opt-6.7b-LoRA&quot;</span> <span class="comment"># 他人针对OPT-6.7B训练好的LoRA参数</span></span><br><span class="line">config = PeftConfig.from_pretrained(peft_model_id)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    config.base_model_name_or_path, return_dict=<span class="literal">True</span>, load_in_8bit=<span class="literal">True</span>, device_map=<span class="string">&quot;auto&quot;</span></span><br><span class="line">)</span><br><span class="line">Tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)</span><br><span class="line"><span class="comment"># 将原始的OPT模型与LoRA参数合并</span></span><br><span class="line">model = PeftModel.from_pretrained(model, peft_model_id)</span><br></pre></td></tr></table></figure>
<h2 id="八、混合专家训练"><a href="#八、混合专家训练" class="headerlink" title="八、混合专家训练"></a>八、混合专家训练</h2><p>混合专家训练（<code>Mixed-of Experts</code>）也是一个比较常用的大模型训练技术，其典型代表是<code>Switch-Transformer</code>模型，如下图所示：</p>
<img src="/post/nlp007/20.jpg" class title="图片">
<p>混合专家是一种比较古老的专家系统方法，对于一个决策问题，交给众多专家进行决策投票，根据投票的结果来进行加权求和实现最终决策。在预训练中，则采用了这种思想。</p>
<p>上图中展示了<code>MoE</code>的单层结构，其中包括一个router和若干个expert。router负责决定给每个expert的权重，并制定权重最高的expert作为当前数据进行前后向传播的路由。例如上图中的<code>FeedForward</code>参数有4个，分别指定了FFN2和FFN1作为当前Batch的路由，此时只会对FFN2和FFN1进行参数更新，而其余的参数则固定不变。</p>
<p>因此可以发现，<code>MoE</code>是一种变相的参数有效性训练方法，只不过不同于<code>LoRA</code>等方法，<code>MoE</code>所引入的参数只是控制路由的，且在推理阶段不再使用router，因此对具体的模型推理能力并不起作用。</p>
<h2 id="九、梯度累积"><a href="#九、梯度累积" class="headerlink" title="九、梯度累积"></a>九、梯度累积</h2><p>梯度累积是一个比较简单的优化技术，其<mark>从<code>Batch size</code>的层面来降低显存占用</mark>。一般情况下，显存的占用直接受到输入数据的影响，包括<code>Batch size</code>、<code>Sequence length</code>等，如果显存溢出，我们最直接的做法就是将<code>Batch size</code>调低。但是对于预训练和指令微调时，扩大<code>Batch size</code>是提高模型训练效果的重要因素，降低<code>Batch size</code>可能会降低模型的效果。</p>
<p>为了不降低<code>Batch size</code>，可以采用梯度累积的方法。<mark style="background-color:red">梯度累积是指在前向传播之后所计算梯度并不立刻用于参数更新，而是接着继续下一轮的前向传播，每次计算的梯度会暂时存储下来，待在若干次前向传播之后，一并对所有梯度进行参数更新。</mark>因此梯度累积相当于是拿时间换空间。</p>
<p><code>HuggingFace</code>的<code>Transformers</code>库中也实现了梯度累积方法，只需要调用如下参数即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--gradient_accumulation_steps=<span class="number">2</span></span><br></pre></td></tr></table></figure><br>例如上面参数“2”的意思是累积两轮的前向传播后计算的梯度值，此时<code>Batch size</code>相当于扩大了1倍，同时训练的总耗时也大约扩大了1倍。</p>
<h2 id="十、梯度检查点"><a href="#十、梯度检查点" class="headerlink" title="十、梯度检查点"></a>十、梯度检查点</h2><p>回顾一下在“<code>DeepSpeed</code>分布式训练”章节中普通的分布式数据并行梯度更新的过程，通常是在前向传播过程中，顺便把每一个参数的梯度预先计算好，并存储下来的。所以在训练过程中，可以直接从显存中提取对应参数的梯度，而无需从模型最顶层依次进行链式推导，起到加速参数更新的作用。但是这种机制是拿空间换时间。现在空间不多，我们必须要再把空间换回来。</p>
<p>梯度检查点的工作原理即使把<mark style="background-color:red">时间换空间</mark>是，即 <mark style="background-color:red"><strong>反向传播重新计算梯度</strong></mark> 。</p>
<blockquote>
<p>先前的方法是提前存储每个神经元的对应的反向传播过程中需要计算的梯度等信息；<br><code>gradient checkpoint</code>旨在不去存储，而是重新计算，从而避免了占用显存，损失了时间。</p>
</blockquote>
<p>在 torch 中使用：把 model 用一个 customize 的 function 包装一下即可，详见：Explore Gradient-Checkpointing in PyTorch<sup>[11]</sup>在 <code>HuggingFace</code> <code>Transformers</code> 中使用：gradient-checkpointing<sup>[12]</sup></p>
<p>总结：<mark style="background-color:red">梯度积累和梯度检查点是相互矛盾的两种方法，一个是省时间、另一个省空间</mark></p>
<h2 id="十一、FlashAttention"><a href="#十一、FlashAttention" class="headerlink" title="十一、FlashAttention"></a>十一、<code>FlashAttention</code></h2><p>最后介绍一个从算法层面上提高显存优化的方法，其由斯坦福大学提出的方法，论文为<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.14135.pdf">@<code>FlashAttention</code>: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p>
<img src="/post/nlp007/21.jpg" class title="图片">
<p>我们知道<code>Self-Attention</code>的计算公式是：</p>
<p>算子主要由“matmul + div + masking + softmax + matmul”几个组成。当Sequence length比较大的时候（例如2048，甚至是GPT-4中的32K），Attention矩阵会是 的空间复杂度，如果在单卡上进行计算，会大量占用显存。</p>
<p><code>Flash Attention</code>则是让Attention的几个算子能够通过分块并行地进行计算，如果这4个算子都能够分块处理，那么就可以实现这一目的，因此下面一一介绍各个算子的分块处理过程。</p>
<p>（1）：矩阵乘积算子，可以采用分块矩阵的方法进行并行计算。如下图所示，两个矩阵相乘，可以用分块矩阵分别在矩阵 的行、 的列（即 的行）上进行滑动，并将滑动的每个分块结果累加即可：</p>
<img src="/post/nlp007/22.jpg" class title="图片">
<p>（2）：这一步需要进行除法操作，因为除法是element-wise的操作，所以非常容易进行分块处理；</p>
<p>（3）：这一步是关键之处，因为涉及到Softmax和乘法操作。特别地，Softmax既不是乘法，也不是element-wise操作，而是对矩阵 的每一行进行归一化，因此需要对该算子单独设计并行处理策略。斯坦福大学团队提出Softmax Tiling策略实现Softmax和乘法算子的并行合并处理。</p>
<blockquote>
<p>譬如我们要计算数组x的softmax。然后我们每次只能算2个数，我们先算第1、2个数的softmax，即 cur_sum = exp(x[0]) + exp(x[1]) y[0:2] = x[0:2] / cur_sum pre_sum = cur_sum 然后我们算第3、4个数的softmax，这时候cur_sum会被更新，之前的sum在变量pre_sum里，这个时候我们可以通过把之前前两个数的softmax结果除以cur_sum/pre_sum来得到正确的结果。如果softmax后面还跟一个matmul的话，上次softmax的结果会和D的一个块乘在一起，然后累积起来，这样我们只需要scale这个累积的值就行。依次类推，在每轮循环都把累积的值scale一下，就能incrementally计算softmax或者softmax + matmul的结果。</p>
</blockquote>
<p>整个<code>Flash Attention</code>的详细算法流程如下所示：</p>
<img src="/post/nlp007/23.jpg" class title="图片">
<p><code>HuggingFace</code>新版本集成了OpenLLaMA库，其中采用了<code>Flash Attention</code>的训练方法，代码可参考：modeling_open_llama.py<sup>[13]</sup></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>[1]<code>Transformer</code> Math 101: <a target="_blank" rel="noopener" href="https://blog.eleuther.ai/">https://blog.eleuther.ai/</a><code>Transformer</code>-math/<br>[2][多图，秒懂]如何训练一个“万亿大模型”？: <a target="_blank" rel="noopener" href="https://blog.csdn.net/cjnewstar111/article/details/128593120">https://blog.csdn.net/cjnewstar111/article/details/128593120</a><br>[3]https://<code>HuggingFace</code>.co/blog/zero-<code>DeepSpeed</code>-fairscale: https://<code>HuggingFace</code>.co/blog/zero-<code>DeepSpeed</code>-fairscale<br>[4]<a target="_blank" rel="noopener" href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/</a>: <a target="_blank" rel="noopener" href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/</a><br>[5]<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/">https://pytorch.org/docs/stable/</a><code>FSDP</code>.html: <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/">https://pytorch.org/docs/stable/</a><code>FSDP</code>.html<br>[6]https://<code>HuggingFace</code>.co/docs/<code>Transformers</code>/v4.27.2/en/main_classes/trainer#<code>Transformers</code>.Trainin: https://<code>HuggingFace</code>.co/docs/<code>Transformers</code>/v4.27.2/en/main_classes/trainer#<code>Transformers</code>.Trainin<br>[7]一文捋顺千亿模型训练技术：流水线并行、张量并行和<code>3D并行</code>: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/617087561">https://zhuanlan.zhihu.com/p/617087561</a><br>[8]量化 | 深度学习Int8的部署推理原理和经验验证: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/509353790">https://zhuanlan.zhihu.com/p/509353790</a><br>[9]<code>INT8量化</code>-介绍（一）: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58182172">https://zhuanlan.zhihu.com/p/58182172</a><br>[10]Finetune_opt_bnb_peft: <a target="_blank" rel="noopener" href="https://github.com/">https://github.com/</a><code>HuggingFace</code>/peft/blob/main/ex<code>AMP</code>les/int8_training/Finetune_opt_bnb_peft.ipynb<br>[11]Explore Gradient-Checkpointing in PyTorch: <a target="_blank" rel="noopener" href="https://qywu.github.io/2019/05/22/explore-gradient-checkpointing.html">https://qywu.github.io/2019/05/22/explore-gradient-checkpointing.html</a><br>[12]gradient-checkpointing: https://<code>HuggingFace</code>.co/docs/<code>Transformers</code>/v4.27.2/en/perf_train_gpu_one#gradient-checkpointing<br>[13]modeling_open_llama.py: <a target="_blank" rel="noopener" href="https://github.com/">https://github.com/</a><code>HuggingFace</code>/<code>Transformers</code>/blob/main/src/<code>Transformers</code>/models/open_llama/modeling_open_llama.py</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://michealxie94.github.io">michealxie94</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://michealxie94.github.io/post/nlp007.html">https://michealxie94.github.io/post/nlp007.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://michealxie94.github.io" target="_blank">michealxie94</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="wechat,weibo,qq,qzone,douban,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/m01.html" title="面经01:北京某科技 机器学习量化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">面经01:北京某科技 机器学习量化</div></div></a></div><div class="next-post pull-right"><a href="/post/LC415.html" title="LC415. 字符串相加"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">LC415. 字符串相加</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">michealxie94</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/michealxie94"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/michealxie94" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:michealxie94@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://www.zhihu.com/" target="_blank" title="Zhihu"><i class="fab fa-zhihu" style="color: #0c5fed;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">2023 不负韶华 ！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E8%BD%BD"><span class="toc-number">1.</span> <span class="toc-text">转载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">2.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81Transformer%E6%A8%A1%E5%9E%8B%E7%AE%97%E5%8A%9B%E8%AF%84%E4%BC%B0"><span class="toc-number">3.</span> <span class="toc-text">一、Transformer模型算力评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83"><span class="toc-number">4.</span> <span class="toc-text">二、混合精度训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81DeepSpeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">三、DeepSpeed分布式训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C"><span class="toc-number">5.1.</span> <span class="toc-text">（1）传统的数据并行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89DeepSpeed-ZeRO-%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">5.2.</span> <span class="toc-text">（2）DeepSpeed ZeRO 并行训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Torch-FSDP-CPU-Offloading"><span class="toc-number">6.</span> <span class="toc-text">四、Torch FSDP + CPU Offloading</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%813D%E5%B9%B6%E8%A1%8C"><span class="toc-number">7.</span> <span class="toc-text">五、3D并行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81INT8%E9%87%8F%E5%8C%96"><span class="toc-number">8.</span> <span class="toc-text">六、INT8量化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%EF%BC%88Scale-Quantization%EF%BC%89"><span class="toc-number">8.1.</span> <span class="toc-text">对称量化（Scale Quantization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%EF%BC%88Affine-Quantization%EF%BC%89"><span class="toc-number">8.2.</span> <span class="toc-text">非对称量化（Affine Quantization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E5%8C%96%E6%84%9F%E7%9F%A5%E8%AE%AD%E7%BB%83%EF%BC%88Quantization-aware-Training%EF%BC%89"><span class="toc-number">8.3.</span> <span class="toc-text">量化感知训练（Quantization-aware Training）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81PEFT"><span class="toc-number">9.</span> <span class="toc-text">七、PEFT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E8%AE%AD%E7%BB%83"><span class="toc-number">10.</span> <span class="toc-text">八、混合专家训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%A2%AF%E5%BA%A6%E7%B4%AF%E7%A7%AF"><span class="toc-number">11.</span> <span class="toc-text">九、梯度累积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9"><span class="toc-number">12.</span> <span class="toc-text">十、梯度检查点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81FlashAttention"><span class="toc-number">13.</span> <span class="toc-text">十一、FlashAttention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">13.1.</span> <span class="toc-text">参考资料</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/4c089154.html" title="LC2811. 判断是否能拆分数组">LC2811. 判断是否能拆分数组</a><time datetime="2023-08-07T08:58:55.000Z" title="发表于 2023-08-07 16:58:55">2023-08-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/LC344.html" title="LC344. 反转字符串">LC344. 反转字符串</a><time datetime="2023-08-07T07:13:18.000Z" title="发表于 2023-08-07 15:13:18">2023-08-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/LC21.html" title="LC21. 合并两个有序链表">LC21. 合并两个有序链表</a><time datetime="2023-08-06T15:51:34.000Z" title="发表于 2023-08-06 23:51:34">2023-08-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/LC24.html" title="LC24. 两两交换链表中的节点">LC24. 两两交换链表中的节点</a><time datetime="2023-08-06T15:51:34.000Z" title="发表于 2023-08-06 23:51:34">2023-08-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/math01.html" title="高等数学">高等数学</a><time datetime="2023-08-01T16:43:53.000Z" title="发表于 2023-08-02 00:43:53">2023-08-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By michealxie94</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://michealxie94.zeabur.app/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://michealxie94.zeabur.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.textContent = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script src="/js/weather.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>